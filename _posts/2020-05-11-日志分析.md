---
layout: post
title:  "日志分析"
subtitle: '日志分析'
date:   2020-05-11 18:00:00
tags: 基础知识
description: '基础知识'
color: 'RGB(255,105,180)'
---



### 日志分析

现阶段大部分企业都会上日志审计设备，在配上流量分光，还有各类IDS、WAF等设备日志，对安全溯源分析十分方便，但在日常工作中，免不了要直接看服务器相关请求日志的情况，这个时候就需要我们自身具备日志分析的能力了。



### 一、日志分析流程

1、统计

首先需要对数据进行处理，如请求IP统计，访问地址统计，HTTP状态码统计等，这些数据统计可以使用excel或者python脚本，如果手头有各类工具那就更容易统计了。

2、威胁发现

关键字过滤：

直接查找在请求中携带的关键字，如script、select、from、echo、bash、.sh等

查看异常请求：

4XX请求、5XX请求

行为分析：

由于日志大概率不会记录post请求体，所以在post请求包体中的攻击往往很难发现，这个时候就需要我们对特定的IP进行行为查看，如查询IP的威胁情报，某个IP登录了多个账号等等

3、报告撰写

在报告中我们重点要体现某个IP或者某些IP的攻击画像，确定这些IP的攻击行为，以便最终确定是否来着同一拨攻击，还是互联网上的肉鸡日常扫描。

ps excel中的数据透视表功能是真的香，谁用谁知道。

### 二、那些年在日志中看到的行为分析

一、恶意IP请求带有多个身份操作

![5-11-1.png](https://i.loli.net/2020/05/11/AbF8d3I2alR15OW.png)

可以看到上述日志中，某IP对登录了邮件并进行了相关操作，可以看到其登录了不同的账户，那么这个时候怎么判断其是正常的请求还是恶意请求呢？

1、威胁情报，查找请求IP相关的威胁情报信息，如果是恶意IP那么大概率就有可能是恶意访问了

2、观察请求中的UA标识，如果UA标识一样，那么是恶意访问的概率就又增加了

3、观察这个IP前的一些请求行为，你就可能发现来着不同IP的登录请求，恶意攻击前的撞库攻击，这时基本就可以坐实了

4、联系相关人员看该IP是否归属自己（太麻烦，一般不会用），可以在二次确认时使用。

二、非正常请求

![5-11-2.png](https://i.loli.net/2020/05/11/9gXn6sr3TDpQAdP.png)

正常业务逻辑不会发送的请求，这些可以通过关键词快速查找过滤

三、扫描行为

![5-11-3.png](https://i.loli.net/2020/05/11/IRrENqjcFfyntX8.png)

通过过滤404请求和GET等，可以发现某些IP的目录扫描探测行为，同时在通过IP去过滤状态码是200的请求，可以发现一些安全隐患。

四、重要接口

![5-11-4.png](https://i.loli.net/2020/05/11/p1iJH4Q2A8cd9Us.png)

可以根据自己的业务类型，对一些敏感接口地址进行查找，观察其访问行为

五、扫描器特征请求

wvs、acunetix、test、appscan、nessus、webreaver、sqlmap、bxss.me等

![5-11-5.png](https://i.loli.net/2020/05/11/uzjKALiHJYtqgcf.png)

bess.me是awvs其中一个XSS扫描插件的地址。部分扫描器带有固定的特征值，需要平时积累发现。

六、关键词查找

select、sleep、echo、bash、down、passwd等

![5-11-6.png](https://i.loli.net/2020/05/11/VXz4LOxF5DbZhl7.png)

使用这些敏感的关键字也能迅速定位攻击请求，上图就是使用sqlmap跑注入所产生的日志

七、一些特征性的请求

![5-11-7.png](https://i.loli.net/2020/05/11/MBJs3RGh2AlzcLi.png)

sqlmap的WAF探测请求



### 三、写报告时注意的点

1、不一定恶意IP的请求就是攻击行为

2、相同的payload在不同的IP请求，可以将其划分同一人

3、部分IP的请求量较低，但存在恶意行为，可能为真实IP（具体可从漏扫成功的地方去跟踪）

4、日志中并无同一地理位置的两个IP同一一个时间区间出现，大概率是可以说是同一人所为

5、查询大量IP，发现威胁情报大多是撞库攻击。这些地址可能不是来自攻击团队，而是来自互联网上的扫描